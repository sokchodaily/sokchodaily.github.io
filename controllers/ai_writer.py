"""
ğŸ¤– AI ê¸°ì‚¬ ì‘ì„± ì—”ì§„ - ì†ì´ˆì¼ë³´ AI ë‰´ìŠ¤ ì‹œìŠ¤í…œ
HWP ë³´ë„ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ì†ì´ˆì¼ë³´ ìŠ¤íƒ€ì¼ì˜ ê¸°ì‚¬ë¥¼ ìë™ ì‘ì„±

ì‘ì„±ì: AI ì‹œìŠ¤í…œ for ê¹€ë„ì—½ ë°œí–‰ì¸
"""

import os
import sys
import logging
import json
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import requests

# AI API ê´€ë ¨ (Google Gemini)
try:
    import google.generativeai as genai
except ImportError:
    print("âš ï¸ Google Generative AI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: pip install google-generativeai")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ai_writer.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class AINewsWriter:
    """
    ğŸ–‹ï¸ AI ê¸°ì‚¬ ì‘ì„± í´ë˜ìŠ¤
    ë³´ë„ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ì†ì´ˆì¼ë³´ ìŠ¤íƒ€ì¼ì˜ ê¸°ì‚¬ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        ğŸ¯ AI ê¸°ì‚¬ ì‘ì„±ê¸° ì´ˆê¸°í™”
        
        Args:
            api_key (str): Google Gemini API í‚¤
        """
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        
        if self.api_key:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash')
            logger.info("ğŸ¤– Google Gemini API ì—°ê²° ì„±ê³µ")
        else:
            self.model = None
            logger.warning("âš ï¸ AI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ í…œí”Œë¦¿ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        
        # ì†ì´ˆì¼ë³´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸
        self.style_guide = {
            'tone': 'ì •í™•í•˜ê³  ê³µì •í•œ',
            'perspective': 'ì§€ì—­ ì£¼ë¯¼ ì¤‘ì‹¬',
            'focus': 'ì†ì´ˆì™€ ê°•ì›ë„ ì§€ì—­',
            'length': '400-800ì',
            'format': 'ìœ¡í•˜ì›ì¹™ ê¸°ë°˜'
        }
        
        # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        self.categories = {
            'ì†ì´ˆì‹œ': 'ì •ì¹˜',
            'ê°•ì›ë„': 'ì •ì¹˜', 
            'êµìœ¡ì²­': 'ì‚¬íšŒ',
            'ë¬¸í™”ì¬ì²­': 'ë¬¸í™”',
            'í•´ì–‘ê²½ì°°ì„œ': 'ì‚¬íšŒ',
            'ê´€ê´‘': 'ê´€ê´‘',
            'ì¶•ì œ': 'ë¬¸í™”',
            'ì˜ˆì‚°': 'ì •ì¹˜',
            'ê°œë°œ': 'ê²½ì œ'
        }
        
        logger.info("ğŸ–‹ï¸ AI ê¸°ì‚¬ ì‘ì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def write_article(self, hwp_data: Dict) -> Dict:
        """
        ğŸ“° ë³´ë„ìë£Œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì‚¬ ì‘ì„±
        
        Args:
            hwp_data (Dict): HWP íŒŒì„œì—ì„œ ì¶”ì¶œí•œ ë°ì´í„°
            
        Returns:
            Dict: ì™„ì„±ëœ ê¸°ì‚¬ ë°ì´í„° (ì œëª©, ë³¸ë¬¸, ë©”íƒ€ë°ì´í„°)
        """
        try:
            logger.info("ğŸ–‹ï¸ AI ê¸°ì‚¬ ì‘ì„± ì‹œì‘")
            
            # 1. ì›ë³¸ ë°ì´í„° ë¶„ì„
            analysis = self._analyze_content(hwp_data)
            
            # 2. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            category = self._classify_category(hwp_data, analysis)
            
            # 3. ê¸°ì‚¬ ì œëª© ìƒì„±
            title = self._generate_title(hwp_data, analysis)
            
            # 4. ê¸°ì‚¬ ë³¸ë¬¸ ì‘ì„±
            content = self._generate_content(hwp_data, analysis)
            
            # 5. ê¸°ì‚¬ ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = self._generate_metadata(hwp_data, analysis, category)
            
            article = {
                'title': title,
                'content': content,
                'category': category,
                'metadata': metadata,
                'source_data': hwp_data,
                'analysis': analysis,
                'created_at': datetime.now().isoformat(),
                'author': 'AI ê¸°ì (ì†ì´ˆì¼ë³´)',
                'status': 'draft'
            }
            
            logger.info(f"âœ… AI ê¸°ì‚¬ ì‘ì„± ì™„ë£Œ: {title}")
            return article
            
        except Exception as e:
            logger.error(f"âŒ AI ê¸°ì‚¬ ì‘ì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _analyze_content(self, hwp_data: Dict) -> Dict:
        """
        ğŸ” ë³´ë„ìë£Œ ë‚´ìš© ë¶„ì„
        """
        text = hwp_data.get('text', '')
        press_info = hwp_data.get('press_release_info', {})
        
        analysis = {
            'key_topics': self._extract_key_topics(text),
            'entities': self._extract_entities(text),
            'agency': press_info.get('agency', ''),
            'urgency': self._assess_urgency(text),
            'impact': self._assess_impact(text),
            'local_relevance': self._assess_local_relevance(text)
        }
        
        logger.info("ğŸ” ë‚´ìš© ë¶„ì„ ì™„ë£Œ")
        return analysis
    
    def _classify_category(self, hwp_data: Dict, analysis: Dict) -> str:
        """
        ğŸ“‚ ê¸°ì‚¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        """
        text = hwp_data.get('text', '').lower()
        agency = analysis.get('agency', '')
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        category_keywords = {
            'ì •ì¹˜': ['ì˜ˆì‚°', 'ì •ì±…', 'ì‹œì¥', 'ë„ì§€ì‚¬', 'ì˜íšŒ', 'ì¡°ë¡€'],
            'ê²½ì œ': ['ì‚¬ì—…', 'íˆ¬ì', 'ê°œë°œ', 'ê¸°ì—…', 'ì¼ìë¦¬', 'ê²½ì œ'],
            'ì‚¬íšŒ': ['êµìœ¡', 'ë³µì§€', 'ì•ˆì „', 'ì˜ë£Œ', 'ì£¼ë¯¼', 'ì‹œë¯¼'],
            'ë¬¸í™”': ['ì¶•ì œ', 'ê³µì—°', 'ì „ì‹œ', 'ë¬¸í™”ì¬', 'ì˜ˆìˆ ', 'ì²´í—˜'],
            'ê´€ê´‘': ['ê´€ê´‘ê°', 'ì—¬í–‰', 'ëª…ì†Œ', 'ìˆ™ë°•', 'ë§›ì§‘', 'ë ˆì €'],
            'ìŠ¤í¬ì¸ ': ['ê²½ê¸°', 'ëŒ€íšŒ', 'ì„ ìˆ˜', 'ì²´ìœ¡', 'ìš´ë™', 'ìŠ¤í¬ì¸ ']
        }
        
        # ë°œì‹ ê¸°ê´€ ê¸°ë°˜ ë¶„ë¥˜
        if agency in self.categories:
            return self.categories[agency]
        
        # í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        scores = {}
        for category, keywords in category_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            scores[category] = score
        
        # ìµœê³  ì ìˆ˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
        best_category = max(scores, key=scores.get) if scores else 'ì‚¬íšŒ'
        
        logger.info(f"ğŸ“‚ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜: {best_category}")
        return best_category
    
    def _generate_title(self, hwp_data: Dict, analysis: Dict) -> str:
        """
        ğŸ“° ê¸°ì‚¬ ì œëª© ìƒì„±
        """
        original_title = hwp_data.get('title', '')
        
        if self.api_key:
            # AIë¥¼ ì‚¬ìš©í•œ ì œëª© ìƒì„±
            title = self._ai_generate_title(hwp_data, analysis)
        else:
            # í…œí”Œë¦¿ ê¸°ë°˜ ì œëª© ìƒì„±
            title = self._template_generate_title(hwp_data, analysis)
        
        # ì œëª© ìµœì í™”
        title = self._optimize_title(title)
        
        logger.info(f"ğŸ“° ì œëª© ìƒì„±: {title}")
        return title
    
    def _generate_content(self, hwp_data: Dict, analysis: Dict) -> str:
        """
        ğŸ“ ê¸°ì‚¬ ë³¸ë¬¸ ìƒì„±
        """
        if self.api_key:
            # AIë¥¼ ì‚¬ìš©í•œ ë³¸ë¬¸ ìƒì„±
            content = self._ai_generate_content(hwp_data, analysis)
        else:
            # í…œí”Œë¦¿ ê¸°ë°˜ ë³¸ë¬¸ ìƒì„±
            content = self._template_generate_content(hwp_data, analysis)
        
        # ë³¸ë¬¸ ìµœì í™”
        content = self._optimize_content(content)
        
        logger.info(f"ğŸ“ ë³¸ë¬¸ ìƒì„± ì™„ë£Œ: {len(content)}ì")
        return content
    
    def _ai_generate_title(self, hwp_data: Dict, analysis: Dict) -> str:
        """
        ğŸ¤– AIë¥¼ ì‚¬ìš©í•œ ì œëª© ìƒì„± (Google Gemini)
        """
        try:
            prompt = f"""
            ë‹¹ì‹ ì€ ì†ì´ˆì¼ë³´ì˜ ì „ë¬¸ ê¸°ìì…ë‹ˆë‹¤. ë‹¤ìŒ ë³´ë„ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì—­ ì£¼ë¯¼ë“¤ì´ ê´€ì‹¬ì„ ê°€ì§ˆ ë§Œí•œ ê¸°ì‚¬ ì œëª©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

            **ì†ì´ˆì¼ë³´ ì œëª© ê°€ì´ë“œë¼ì¸:**
            - ì†ì´ˆì™€ ê°•ì›ë„ ì§€ì—­ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ê°•ì¡°
            - 50ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
            - ì •í™•í•˜ê³  ê°ê´€ì ì¸ í‘œí˜„ ì‚¬ìš©
            - ì§€ì—­ ì£¼ë¯¼ì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” ë‚´ìš©

            **ë³´ë„ìë£Œ ë‚´ìš©:**
            ì œëª©: {hwp_data.get('title', '')}
            ë°œì‹ ê¸°ê´€: {analysis.get('agency', '')}
            ì£¼ìš” ë‚´ìš©: {hwp_data.get('text', '')[:500]}...

            **ìƒì„±í•  ì œëª©ë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”:**
            """
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=100,
                    temperature=0.7
                )
            )
            
            title = response.text.strip()
            return title
            
        except Exception as e:
            logger.warning(f"âš ï¸ AI ì œëª© ìƒì„± ì‹¤íŒ¨, í…œí”Œë¦¿ ì‚¬ìš©: {e}")
            return self._template_generate_title(hwp_data, analysis)
    
    def _ai_generate_content(self, hwp_data: Dict, analysis: Dict) -> str:
        """
        ğŸ¤– AIë¥¼ ì‚¬ìš©í•œ ë³¸ë¬¸ ìƒì„± (Google Gemini)
        """
        try:
            prompt = f"""
            ë‹¹ì‹ ì€ ì†ì´ˆì¼ë³´ì˜ ì „ë¬¸ ê¸°ìì…ë‹ˆë‹¤. ë‹¤ìŒ ë³´ë„ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì—­ ì£¼ë¯¼ë“¤ì„ ìœ„í•œ ê¸°ì‚¬ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

            **ì†ì´ˆì¼ë³´ ê¸°ì‚¬ ìŠ¤íƒ€ì¼:**
            - ìœ¡í•˜ì›ì¹™(ëˆ„ê°€, ì–¸ì œ, ì–´ë””ì„œ, ë¬´ì—‡ì„, ì™œ, ì–´ë–»ê²Œ) ì¤€ìˆ˜
            - ì§€ì—­ ì£¼ë¯¼ì˜ ì‹œê°ì—ì„œ ì‘ì„±
            - ì†ì´ˆì™€ ê°•ì›ë„ ì§€ì—­ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì¤‘ì  ì„œìˆ 
            - 400-600ì ë¶„ëŸ‰
            - ì •í™•í•˜ê³  ê³µì •í•œ ë³´ë„

            **ë³´ë„ìë£Œ ì •ë³´:**
            ë°œì‹ ê¸°ê´€: {analysis.get('agency', '')}
            ì›ë¬¸: {hwp_data.get('text', '')}

            **ê¸°ì‚¬ ì‘ì„± ìš”êµ¬ì‚¬í•­:**
            1. ë¦¬ë“œ ë¬¸ë‹¨: í•µì‹¬ ë‚´ìš© ìš”ì•½
            2. ì„¸ë¶€ ë‚´ìš©: êµ¬ì²´ì ì¸ ì„¤ëª…
            3. ë°°ê²½/ì˜ë¯¸: ì§€ì—­ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
            4. ë§ˆë¬´ë¦¬: í–¥í›„ ì „ë§ì´ë‚˜ ì£¼ë¯¼ ë°˜ì‘

            **ê¸°ì‚¬ ë³¸ë¬¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”:**
            """
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=800,
                    temperature=0.6
                )
            )
            
            content = response.text.strip()
            return content
            
        except Exception as e:
            logger.warning(f"âš ï¸ AI ë³¸ë¬¸ ìƒì„± ì‹¤íŒ¨, í…œí”Œë¦¿ ì‚¬ìš©: {e}")
            return self._template_generate_content(hwp_data, analysis)
    
    def _template_generate_title(self, hwp_data: Dict, analysis: Dict) -> str:
        """
        ğŸ“ í…œí”Œë¦¿ ê¸°ë°˜ ì œëª© ìƒì„± (AI ë¯¸ì‚¬ìš©ì‹œ)
        """
        original_title = hwp_data.get('title', '')
        agency = analysis.get('agency', '')
        
        # ê¸°ë³¸ ì œëª© ì •ë¦¬
        title = original_title
        
        # ì§€ì—­ ê´€ë ¨ í‚¤ì›Œë“œ ê°•ì¡°
        if 'ì†ì´ˆ' not in title and agency == 'ì†ì´ˆì‹œ':
            title = f"ì†ì´ˆì‹œ, {title}"
        elif 'ê°•ì›ë„' not in title and agency == 'ê°•ì›ë„':
            title = f"ê°•ì›ë„, {title}"
        
        # ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ ì œê±°
        title = re.sub(r'ë³´ë„ìë£Œ|ê³µì§€|ì•Œë¦¼', '', title).strip()
        
        # ê¸¸ì´ ì œí•œ
        if len(title) > 50:
            title = title[:47] + "..."
        
        return title or "ì œëª© ì—†ìŒ"
    
    def _template_generate_content(self, hwp_data: Dict, analysis: Dict) -> str:
        """
        ğŸ“ í…œí”Œë¦¿ ê¸°ë°˜ ë³¸ë¬¸ ìƒì„± (AI ë¯¸ì‚¬ìš©ì‹œ)
        """
        original_text = hwp_data.get('text', '')
        agency = analysis.get('agency', '')
        
        # ê¸°ë³¸ ê¸°ì‚¬ êµ¬ì¡°
        content_parts = []
        
        # ë¦¬ë“œ ë¬¸ë‹¨
        lead = f"{agency}ê°€ ìƒˆë¡œìš´ ì†Œì‹ì„ ë°œí‘œí–ˆë‹¤."
        content_parts.append(lead)
        
        # ë³¸ë¬¸ (ì›ë¬¸ì—ì„œ ì£¼ìš” ë‚´ìš© ì¶”ì¶œ)
        sentences = re.split(r'[.!?]', original_text)
        main_content = []
        
        for sentence in sentences[:5]:  # ìƒìœ„ 5ê°œ ë¬¸ì¥
            cleaned = sentence.strip()
            if len(cleaned) > 10:  # ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ë§Œ
                main_content.append(cleaned + ".")
        
        if main_content:
            content_parts.extend(main_content)
        
        # ë§ˆë¬´ë¦¬
        closing = f"ì´ë²ˆ ë°œí‘œëŠ” ì†ì´ˆ ì§€ì—­ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤."
        content_parts.append(closing)
        
        return '\n\n'.join(content_parts)
    
    def _generate_metadata(self, hwp_data: Dict, analysis: Dict, category: str) -> Dict:
        """
        ğŸ“Š ê¸°ì‚¬ ë©”íƒ€ë°ì´í„° ìƒì„±
        """
        metadata = {
            'category': category,
            'tags': self._generate_tags(hwp_data, analysis),
            'location': 'ì†ì´ˆ',
            'source': analysis.get('agency', ''),
            'urgency': analysis.get('urgency', 'normal'),
            'images': len(hwp_data.get('images', [])),
            'word_count': len(hwp_data.get('text', '')),
            'reading_time': f"{max(1, len(hwp_data.get('text', '')) // 300)}ë¶„"
        }
        
        return metadata
    
    def _extract_key_topics(self, text: str) -> List[str]:
        """
        ğŸ”‘ ì£¼ìš” í† í”½ ì¶”ì¶œ
        """
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (TF-IDFë‚˜ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥)
        topics = []
        keywords = ['ì†ì´ˆ', 'ê°•ì›ë„', 'ì‹œë¯¼', 'ì£¼ë¯¼', 'ê°œë°œ', 'ë¬¸í™”', 'ê´€ê´‘', 'êµìœ¡', 'ë³µì§€']
        
        for keyword in keywords:
            if keyword in text:
                topics.append(keyword)
        
        return topics[:5]  # ìƒìœ„ 5ê°œë§Œ
    
    def _extract_entities(self, text: str) -> List[str]:
        """
        ğŸ¢ ê°œì²´ëª… ì¶”ì¶œ (ê¸°ê´€ëª…, ì¸ëª…, ì§€ëª… ë“±)
        """
        entities = []
        
        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ê¸°ë³¸ì ì¸ ê°œì²´ëª… ì¶”ì¶œ
        patterns = {
            'ê¸°ê´€': r'(ì†ì´ˆì‹œ|ê°•ì›ë„|êµìœ¡ì²­|í•´ì–‘ê²½ì°°ì„œ|ë¬¸í™”ì¬ì²­)',
            'ì¸ëª…': r'([ê°€-í£]{2,3})\s*(ì‹œì¥|ë„ì§€ì‚¬|ì²­ì¥|ê³¼ì¥)',
            'ì§€ëª…': r'(ì†ì´ˆ|ê°•ë¦‰|ì¶˜ì²œ|ì›ì£¼|ë™í•´|íƒœë°±)'
        }
        
        for entity_type, pattern in patterns.items():
            matches = re.findall(pattern, text)
            entities.extend(matches)
        
        return list(set(entities))  # ì¤‘ë³µ ì œê±°
    
    def _assess_urgency(self, text: str) -> str:
        """
        âš¡ ê¸´ê¸‰ë„ í‰ê°€
        """
        urgent_keywords = ['ê¸´ê¸‰', 'ì¦‰ì‹œ', 'ì‹ ì†', 'ì¡°ì†', 'ìš°ì„ ']
        normal_keywords = ['ì¶”ì§„', 'ê³„íš', 'ì˜ˆì •', 'ì§„í–‰']
        
        urgent_count = sum(1 for keyword in urgent_keywords if keyword in text)
        
        if urgent_count > 0:
            return 'urgent'
        else:
            return 'normal'
    
    def _assess_impact(self, text: str) -> str:
        """
        ğŸ“Š ì˜í–¥ë„ í‰ê°€
        """
        high_impact_keywords = ['ëŒ€ê·œëª¨', 'ì „ì²´', 'ëª¨ë“ ', 'ì „ë©´', 'ëŒ€í­']
        medium_impact_keywords = ['ì¼ë¶€', 'ë¶€ë¶„', 'ê°œì„ ', 'í™•ëŒ€']
        
        high_count = sum(1 for keyword in high_impact_keywords if keyword in text)
        medium_count = sum(1 for keyword in medium_impact_keywords if keyword in text)
        
        if high_count > 0:
            return 'high'
        elif medium_count > 0:
            return 'medium'
        else:
            return 'low'
    
    def _assess_local_relevance(self, text: str) -> float:
        """
        ğŸ  ì§€ì—­ ê´€ë ¨ì„± í‰ê°€ (0-1 ì‚¬ì´ ì ìˆ˜)
        """
        local_keywords = ['ì†ì´ˆ', 'ê°•ì›ë„', 'ì§€ì—­', 'ì£¼ë¯¼', 'ì‹œë¯¼', 'ë™í•´', 'ì„¤ì•…ì‚°']
        
        total_words = len(text.split())
        local_mentions = sum(1 for keyword in local_keywords if keyword in text)
        
        relevance = min(1.0, local_mentions / max(1, total_words * 0.1))
        return relevance
    
    def _generate_tags(self, hwp_data: Dict, analysis: Dict) -> List[str]:
        """
        ğŸ·ï¸ ê¸°ì‚¬ íƒœê·¸ ìƒì„±
        """
        tags = []
        
        # ê¸°ë³¸ íƒœê·¸
        agency = analysis.get('agency', '')
        if agency:
            tags.append(agency)
        
        # í† í”½ ê¸°ë°˜ íƒœê·¸
        tags.extend(analysis.get('key_topics', []))
        
        # ê°œì²´ëª… ê¸°ë°˜ íƒœê·¸
        tags.extend(analysis.get('entities', [])[:3])  # ìƒìœ„ 3ê°œë§Œ
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
        tags = list(set(tags))
        tags = [tag for tag in tags if len(tag) > 1]  # 1ê¸€ì íƒœê·¸ ì œì™¸
        
        return tags[:8]  # ìµœëŒ€ 8ê°œ
    
    def _optimize_title(self, title: str) -> str:
        """
        âœ¨ ì œëª© ìµœì í™”
        """
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        title = re.sub(r'\s+', ' ', title).strip()
        
        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        title = re.sub(r'[""''`]', '"', title)
        
        # ê¸¸ì´ ì œí•œ
        if len(title) > 80:
            title = title[:77] + "..."
        
        return title
    
    def _optimize_content(self, content: str) -> str:
        """
        âœ¨ ë³¸ë¬¸ ìµœì í™”
        """
        # ë¬¸ë‹¨ ì •ë¦¬
        content = re.sub(r'\n\s*\n', '\n\n', content)
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        content = re.sub(r' +', ' ', content)
        
        # ë¬¸ì¥ ë ì •ë¦¬
        content = re.sub(r'\.+', '.', content)
        
        return content.strip()
    
    def save_article(self, article: Dict, output_dir: str = "_posts") -> str:
        """
        ğŸ’¾ ì™„ì„±ëœ ê¸°ì‚¬ë¥¼ Jekyll í¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥
        
        Args:
            article (Dict): ì™„ì„±ëœ ê¸°ì‚¬ ë°ì´í„°
            output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
            
        Returns:
            str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # Jekyll í¬ìŠ¤íŠ¸ íŒŒì¼ëª… í˜•ì‹: YYYY-MM-DD-title.md
            date_str = datetime.now().strftime("%Y-%m-%d")
            title_slug = re.sub(r'[^\wê°€-í£]', '-', article['title'])[:50]
            filename = f"{date_str}-{title_slug}.md"
            
            output_path = Path(output_dir) / filename
            output_path.parent.mkdir(exist_ok=True)
            
            # Jekyll Front Matter ìƒì„±
            front_matter = {
                'layout': 'post',
                'title': article['title'],
                'date': datetime.now().strftime("%Y-%m-%d %H:%M:%S +0900"),
                'category': article['category'],
                'author': article['author'],
                'tags': article['metadata']['tags'],
                'source': article['metadata']['source'],
                'location': article['metadata']['location']
            }
            
            # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„±
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("---\n")
                for key, value in front_matter.items():
                    if isinstance(value, list):
                        f.write(f"{key}: {value}\n")
                    else:
                        f.write(f"{key}: \"{value}\"\n")
                f.write("---\n\n")
                f.write(article['content'])
            
            logger.info(f"ğŸ’¾ ê¸°ì‚¬ ì €ì¥ ì™„ë£Œ: {output_path}")
            return str(output_path)
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ì‚¬ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise


def main():
    """
    ğŸ§ª AI ê¸°ì‚¬ ì‘ì„±ê¸° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    """
    # í…ŒìŠ¤íŠ¸ìš© HWP ë°ì´í„° (ì‹¤ì œë¡œëŠ” HWPParserì—ì„œ ê°€ì ¸ì˜´)
    test_hwp_data = {
        'title': 'ì†ì´ˆì‹œ 2025ë…„ ê´€ê´‘ í™œì„±í™” ê³„íš ë°œí‘œ',
        'text': 'ì†ì´ˆì‹œê°€ 2025ë…„ ê´€ê´‘ í™œì„±í™”ë¥¼ ìœ„í•œ ì¢…í•©ê³„íšì„ ë°œí‘œí–ˆë‹¤. ì´ë²ˆ ê³„íšì—ëŠ” í•´ìˆ˜ìš•ì¥ ì‹œì„¤ ê°œì„ ê³¼ ì„¤ì•…ì‚° ì¼€ì´ë¸”ì¹´ ê²€í† ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤.',
        'images': [],
        'metadata': {'filename': 'test.hwp'},
        'press_release_info': {'agency': 'ì†ì´ˆì‹œ'}
    }
    
    # AI ê¸°ì‚¬ ì‘ì„±ê¸° ì´ˆê¸°í™”
    writer = AINewsWriter()
    
    # ê¸°ì‚¬ ì‘ì„±
    article = writer.write_article(test_hwp_data)
    
    print("ğŸ‰ AI ê¸°ì‚¬ ì‘ì„± ê²°ê³¼:")
    print(f"ğŸ“° ì œëª©: {article['title']}")
    print(f"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {article['category']}")
    print(f"ğŸ“ ë³¸ë¬¸: {article['content'][:200]}...")
    print(f"ğŸ·ï¸ íƒœê·¸: {article['metadata']['tags']}")
    
    # ê¸°ì‚¬ ì €ì¥
    saved_path = writer.save_article(article)
    print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {saved_path}")


if __name__ == "__main__":
    main() 